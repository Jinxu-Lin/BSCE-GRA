{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgngvunjJlMo"
      },
      "source": [
        "Generated partially with ChatGPT (chat.openai.com).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d865RY5uHWNZ"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import multivariate_normal\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_4Pm4zHPISDZ"
      },
      "outputs": [],
      "source": [
        "# Define a custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "# Define the dataset\n",
        "class MoGData(object):\n",
        "  def __init__(self, dimension=2, num_classes=2, magnitude=10):\n",
        "    # Define the parameters for the two Gaussian distributions\n",
        "    self.dimension = dimension\n",
        "    self.num_classes = num_classes\n",
        "    self.magnitude = magnitude\n",
        "    self.mu = np.zeros((num_classes, dimension))\n",
        "    self.sigma = np.zeros((num_classes, dimension, dimension))\n",
        "    self.distrib = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "      for j in range(dimension):\n",
        "        self.mu[i, j] = np.random.uniform(-self.magnitude, self.magnitude)\n",
        "      # Identity matrix for variance\n",
        "      self.sigma[i] = np.eye(dimension)  \n",
        "      self.distrib.append(multivariate_normal(mean=self.mu[i], cov=self.sigma[i]))\n",
        "\n",
        "  def sample_data(self, num_samples = 10000):\n",
        "    # Generate samples from the two Gaussian distributions\n",
        "    samples = []\n",
        "    for i in range(self.num_classes):\n",
        "      samples.append(np.random.multivariate_normal(self.mu[i], self.sigma[i], num_samples))\n",
        "\n",
        "    # Combine the samples and create labels\n",
        "    data = np.concatenate(samples).astype(np.float32)\n",
        "    labels = np.concatenate([[i]*num_samples for i in range(self.num_classes)]).astype(int)\n",
        "\n",
        "    # Shuffle the data and labels together\n",
        "    combined = list(zip(data, labels))\n",
        "    data[:], labels[:] = zip(*combined)\n",
        "    return data, labels\n",
        "  \n",
        "  def plot(self, num_samples):\n",
        "    data, labels = self.sample_data(num_samples)\n",
        "    fig = plt.figure()\n",
        "    \n",
        "    if self.dimension == 3:\n",
        "      ax = fig.add_subplot(111, projection='3d')\n",
        "      for i in range(self.num_classes):\n",
        "        samples = data[labels==i]\n",
        "        color = np.random.rand(3)\n",
        "        ax.scatter(samples[:, 0], samples[:, 1], samples[:, 2], c=[color], label='class '+str(i), alpha=0.05)\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "    elif self.dimension == 2:\n",
        "      for i in range(self.num_classes):\n",
        "        samples = data[labels==i]\n",
        "        color = np.random.rand(3)\n",
        "        plt.scatter(samples[:, 0], samples[:, 1], c=color, label='class '+str(i), alpha=0.05)\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "    else:\n",
        "      print(\"Dimension not supported\")\n",
        "\n",
        "  def compute_likelihood_ratio(self, labels, data_points):\n",
        "    \"\"\"p(y=0|x), assuming p(y=0)=p(y=1)=0.5\"\"\"\n",
        "    # 计算所有数据点在每个类别分布下的pdf值\n",
        "    distances = np.array([self.distrib[j].pdf(data_points) for j in range(self.num_classes)]).T\n",
        "    \n",
        "    # 获取每个数据点对应类别的pdf值\n",
        "    gt_probs = distances[np.arange(data_points.shape[0]), labels] / distances.sum(axis=1)\n",
        "    \n",
        "    return gt_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset Initialization\n",
        "\n",
        "seed = 18222\n",
        "set_seed(seed)\n",
        "\n",
        "num_samples = 10000\n",
        "batch_size = 1000\n",
        "dimension = 2\n",
        "num_classes = 100\n",
        "magnitude = 10\n",
        "\n",
        "mog_data = MoGData(dimension=dimension, num_classes=num_classes, magnitude=magnitude)\n",
        "# mog_data.plot(num_samples=3000)\n",
        "train_loader = DataLoader(CustomDataset(*mog_data.sample_data(num_samples=num_samples)),\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "# generate a test dataset from the distribution\n",
        "test_data, test_labels = mog_data.sample_data(num_samples=1000)\n",
        "test_gt_probs = mog_data.compute_likelihood_ratio(test_labels, test_data)\n",
        "test_labels = torch.from_numpy(test_labels).long().cuda()\n",
        "test_gt_probs = torch.from_numpy(test_gt_probs).cuda()\n",
        "\n",
        "test_data_tensor = torch.from_numpy(test_data).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the DNN model\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(DNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        \n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define custom loss functions\n",
        "class CrossEntropy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CrossEntropy, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "\n",
        "        target = target.view(-1, 1)\n",
        "        logpt = F.log_softmax(input, dim=1)\n",
        "        logpt = logpt.gather(1, target)\n",
        "        logpt = logpt.view(-1)\n",
        "        loss = -1 * logpt\n",
        "\n",
        "        return loss.mean()\n",
        "    \n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "    def forward(self, input, target):\n",
        "\n",
        "        target = target.view(-1,1)\n",
        "        logpt = F.log_softmax(input, dim=1)\n",
        "        logpt = logpt.gather(1,target)\n",
        "        logpt = logpt.view(-1)\n",
        "\n",
        "        pt = logpt.exp()\n",
        "\n",
        "        # Get the correct class probability\n",
        "        # Eg if target is 0, gt_prob is prob(0) = |0 - prob(0)|\n",
        "        # If target is 1, gt_prob is prob(1) = |1 - prob(0)|\n",
        "        # gt_prob = (target-gt_prob).abs()\n",
        "\n",
        "        weight = (1 - pt).abs()**self.gamma\n",
        "        # weight = (1-pt)**self.gamma\n",
        "        \n",
        "        loss = -1 * weight * logpt\n",
        "\n",
        "        return loss.mean()\n",
        "\n",
        "\n",
        "class CrossEntropyProb(nn.Module):\n",
        "    def __init__(self, gamma=2):\n",
        "        super(CrossEntropyProb, self).__init__()\n",
        "        self.gamma = gamma\n",
        "    def forward(self, input, target, gt_prob):\n",
        "\n",
        "        target = target.view(-1,1)\n",
        "        logpt = F.log_softmax(input, dim=1)\n",
        "        logpt = logpt.gather(1,target)\n",
        "        logpt = logpt.view(-1)\n",
        "\n",
        "        pt = logpt.exp()\n",
        "\n",
        "        # Get the correct class probability\n",
        "        # Eg if target is 0, gt_prob is prob(0) = |0 - prob(0)|\n",
        "        # If target is 1, gt_prob is prob(1) = |1 - prob(0)|\n",
        "        # gt_prob = (target-gt_prob).abs()\n",
        "        # with torch.no_grad():\n",
        "        weight = (gt_prob - pt).abs()**self.gamma\n",
        "        # weight = (1-pt)**self.gamma\n",
        "        \n",
        "        loss = -1 * weight * logpt\n",
        "\n",
        "        return loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "q2W3kjyfHzfd",
        "outputId": "abe5fb16-95cc-4e8f-992a-862a8abd2bd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:01<00:00, 623.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross Entropy Consistency:  0.22408372866744825\n",
            "Cross Entropy Accuracy:  0.19664999842643738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1\n",
        "\n",
        "# Training the model with cross entropy loss\n",
        "model_ce = DNN(dimension, 10, num_classes).cuda()  # Move model to GPU\n",
        "ce = CrossEntropy().cuda()  # Move loss function to GPU\n",
        "optimizer_ce = optim.SGD(model_ce.parameters(), lr=learning_rate)\n",
        "pbar_ce = tqdm(total=len(train_loader))\n",
        "\n",
        "for i, (inputs, labels) in enumerate(train_loader):\n",
        "  inputs, labels = inputs.cuda(), labels.cuda()  # Move data to GPU\n",
        "  optimizer_ce.zero_grad()\n",
        "  outputs = model_ce(inputs)\n",
        "  loss_ce = ce(outputs, labels)\n",
        "  loss_ce.backward()\n",
        "  optimizer_ce.step()\n",
        "  pbar_ce.update(1)\n",
        "pbar_ce.close()\n",
        "\n",
        "test_outputs_ce = model_ce(test_data_tensor)\n",
        "prob_ce = F.softmax(test_outputs_ce, dim=1)\n",
        "confidence = prob_ce.gather(1, test_labels.unsqueeze(1)).squeeze(1)\n",
        "calibrated_error_ce = test_gt_probs - confidence\n",
        "print(\"Cross Entropy Consistency: \", calibrated_error_ce.abs().mean().item())\n",
        "\n",
        "accuracy = (prob_ce.argmax(dim=1) == test_labels).float().mean().item()\n",
        "print(\"Cross Entropy Accuracy: \", accuracy)\n",
        "# 假设你的模型变量名是 model\n",
        "del model_ce, ce, inputs, labels, outputs, loss_ce, test_outputs_ce, prob_ce, calibrated_error_ce, optimizer_ce, pbar_ce\n",
        "\n",
        "# 强制进行垃圾回收\n",
        "gc.collect()\n",
        "\n",
        "# 清空 CUDA 缓存\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/500 [00:14<?, ?it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 515.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Focal Loss Consistency:  0.07503033895370594\n"
          ]
        }
      ],
      "source": [
        "# Training the model with cross entropy loss\n",
        "gamma = 2\n",
        "model_fl = DNN(dimension, 10, num_classes).cuda()  # Move model to GPU\n",
        "fl = FocalLoss(gamma=gamma).cuda()  # Move loss function to GPU\n",
        "optimizer_fl = optim.SGD(model_fl.parameters(), lr=learning_rate)\n",
        "pbar_fl = tqdm(total=len(train_loader))\n",
        "\n",
        "for i, (inputs, labels) in enumerate(train_loader):\n",
        "  inputs, labels = inputs.cuda(), labels.cuda()  # Move data to GPU\n",
        "  optimizer_fl.zero_grad()\n",
        "  outputs = model_fl(inputs)\n",
        "  loss_fl = fl(outputs, labels)\n",
        "  loss_fl.backward()\n",
        "  optimizer_fl.step()\n",
        "  pbar_fl.update(1)\n",
        "pbar_fl.close()\n",
        "\n",
        "test_outputs_fl = model_fl(test_data_tensor)\n",
        "prob_fl = F.softmax(test_outputs_fl, dim=1)\n",
        "consistency_fl = test_gt_probs - prob_fl[:, 0]\n",
        "print(\"Focal Loss Consistency: \", consistency_fl.abs().mean().item())\n",
        "\n",
        "del model_fl, fl, inputs, labels, outputs, loss_fl, test_outputs_fl, prob_fl, consistency_fl, optimizer_fl, pbar_fl\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 238.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gamma:  1 Cross Entropy Probability Consistency:  0.16383511643978158 Accuracy:  0.2842999994754791\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# from 1 to 10, step 0.1\n",
        "gamma_list = [1]\n",
        "\n",
        "for gamma in gamma_list:\n",
        "  # Training the model with cross entropy probability loss\n",
        "  model_ce_prob = DNN(dimension, 10, num_classes).cuda()\n",
        "  optimizer_ce_prob = optim.SGD(model_ce_prob.parameters(), lr=learning_rate)\n",
        "  pbar_ce_prob = tqdm(total=len(train_loader))\n",
        "  ce_prob = CrossEntropyProb(gamma=gamma).cuda()\n",
        "\n",
        "  for i, (inputs, labels) in enumerate(train_loader):\n",
        "    inputs = inputs.cuda()\n",
        "    labels = labels.cuda()\n",
        "    optimizer_ce_prob.zero_grad()\n",
        "    outputs = model_ce_prob(inputs)\n",
        "    # print(outputs[0])\n",
        "    # print(labels[0])\n",
        "    gt_probs = mog_data.compute_likelihood_ratio(labels.cpu(), inputs.cpu()) \n",
        "    gt_probs = torch.from_numpy(gt_probs).cuda()\n",
        "    loss_prob = ce_prob(outputs, labels, gt_probs)\n",
        "    loss_prob.backward()\n",
        "    optimizer_ce_prob.step()\n",
        "    pbar_ce_prob.update(1)\n",
        "  pbar_ce_prob.close()\n",
        "\n",
        "  test_outputs_ce_prob = model_ce_prob(test_data_tensor)\n",
        "  prob_ce_prob = F.softmax(test_outputs_ce_prob, dim=1)\n",
        "  confidence = prob_ce_prob.gather(1, test_labels.unsqueeze(1)).squeeze(1) \n",
        "  calibrated_error_ce_prob = test_gt_probs - confidence\n",
        "  accuracy = (prob_ce_prob.argmax(dim=1) == test_labels).float().mean().item()\n",
        "  print(\"gamma: \", gamma, \"Cross Entropy Probability Consistency: \", calibrated_error_ce_prob.abs().mean().item(), \"Accuracy: \", accuracy)\n",
        "\n",
        "  del model_ce_prob, ce_prob, optimizer_ce_prob, pbar_ce_prob, test_outputs_ce_prob, prob_ce_prob, calibrated_error_ce_prob\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# generate a test dataset from the distribution\n",
        "test_data, test_labels = mog_data.sample_data(num_samples=1000000)\n",
        "test_gt_probs = mog_data.compute_likelihood_ratio(test_labels, test_data)\n",
        "test_labels = torch.from_numpy(test_labels).long()\n",
        "test_gt_probs = torch.from_numpy(test_gt_probs)\n",
        "\n",
        "test_outputs_ce = model_ce(torch.from_numpy(test_data))\n",
        "prob_ce = F.softmax(test_outputs_ce)\n",
        "consistency_ce =test_gt_probs-prob_ce[:,0]\n",
        "print(consistency_ce.abs().mean())\n",
        "\n",
        "test_outputs_ce_prob = model_ce_prob(torch.from_numpy(test_data))\n",
        "prob_ce_prob = F.softmax(test_outputs_ce_prob)\n",
        "consistency_ce_prob =test_gt_probs-prob_ce_prob[:,0]\n",
        "print(consistency_ce_prob.abs().mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model_ce' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_labels)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# get the prediction \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m test_outputs_ce \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_ce\u001b[49m(test_data)\n\u001b[1;32m      8\u001b[0m test_pred_probs_ce \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(F\u001b[38;5;241m.\u001b[39msoftmax(test_outputs_ce, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m test_pred_labels_ce \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(test_outputs_ce, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_ce' is not defined"
          ]
        }
      ],
      "source": [
        "# generate a test dataset from the distribution\n",
        "test_data, test_labels = mog_data.sample_data(num_samples=10000)\n",
        "test_data = torch.from_numpy(test_data).cuda()\n",
        "test_labels = torch.from_numpy(test_labels).long().cuda()\n",
        "\n",
        "# get the prediction \n",
        "test_outputs_ce = model_ce(test_data)\n",
        "test_pred_probs_ce = torch.max(F.softmax(test_outputs_ce, dim=1), dim=1)[0]\n",
        "test_pred_labels_ce = torch.max(test_outputs_ce, dim=1)[1]\n",
        "\n",
        "test_outputs_ce_prob = model_ce_prob(test_data)\n",
        "test_pred_probs_ce_prob = torch.max(F.softmax(test_outputs_ce_prob, dim=1), dim=1)[0]\n",
        "test_pred_labels_ce_prob = torch.max(test_outputs_ce_prob, dim=1)[1]\n",
        "\n",
        "accuracy_ce = (test_pred_labels_ce == test_labels).float().mean().item()\n",
        "accuracy_ce_prob = (test_pred_labels_ce_prob == test_labels).float().mean().item()\n",
        "print(f\"Accuracy: {accuracy_ce:.4f}\")\n",
        "print(f\"Accuracy: {accuracy_ce_prob:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMKn-ya_Jg1Y",
        "outputId": "1652dd3a-bc6e-456f-9c94-719d2636da41"
      },
      "outputs": [],
      "source": [
        "def generate_mesh(min_x, max_x, min_y, max_y, num_x, num_y):\n",
        "  # Define the range of x and y values\n",
        "  x_range = np.linspace(-5, 5, num_x)\n",
        "  y_range = np.linspace(-5, 5, num_y)\n",
        "\n",
        "  # Generate the grid of points\n",
        "  X, Y = np.meshgrid(x_range, y_range)\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "\n",
        "  mesh = np.stack((X.reshape(-1),Y.reshape(-1)), axis=1)\n",
        "  print(mesh.shape)\n",
        "  return mesh\n",
        "\n",
        "min_x = min_y = -500\n",
        "max_x = max_y = 500\n",
        "num_x = num_y = 101\n",
        "\n",
        "mesh_np = generate_mesh(min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y, num_x=num_x, num_y=num_y).astype(np.float32)\n",
        "\n",
        "inputs = torch.from_numpy(mesh_np)\n",
        "outputs = model_ce(inputs)\n",
        "pred_probs = F.softmax(outputs)[:, 0].detach().numpy()\n",
        "print(mesh_np.shape)\n",
        "print(mesh_np[100])\n",
        "gt_probs = mog_data.compute_likelihood_ratio(mesh_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# set_seed(18222)\n",
        "\n",
        "\n",
        "# Select points with probabilities between 0.8 and 0.85, give back the indices\n",
        "selected_indices = torch.where((test_pred_probs > 0.7) & (test_pred_probs < 0.85))\n",
        "# selected_indices = torch.where(test_pred_probs > 0.0)\n",
        "\n",
        "# randomly sample 1 number from the selected indices\n",
        "poi_index = random.choice(selected_indices[0].numpy())\n",
        "poi_data = test_data[poi_index]\n",
        "poi_label = test_labels[poi_index]\n",
        "poi_pred_prob = test_pred_probs[poi_index]\n",
        "poi_pred_label = test_pred_labels[poi_index]\n",
        "\n",
        "# compute the likelihood ratio for the poi_data\n",
        "poi_gt_prob = mog_data.compute_likelihood_ratio(poi_data) if poi_pred_label == 0 else 1 - mog_data.compute_likelihood_ratio(poi_data)\n",
        "\n",
        "print(f\"The POI is {poi_data} with label {poi_label} and prediction probability {poi_pred_prob} and prediction label {poi_pred_label}\")\n",
        "print(f\"The ground truth probability of the POI is {poi_gt_prob}\")\n",
        "\n",
        "# get the points with confidence around poi_pred_prob less than 0.01\n",
        "confidence_gap = 0.03\n",
        "confidence_high_threshold = poi_pred_prob + confidence_gap/2\n",
        "confidence_low_threshold = poi_pred_prob - confidence_gap/2\n",
        "# get the indices of the points with confidence around poi_pred_prob less than 0.01\n",
        "confidence_indices = torch.where((test_pred_probs > confidence_low_threshold) & (test_pred_probs < confidence_high_threshold))\n",
        "calibration_error_acc = (test_pred_labels[confidence_indices] == test_labels[confidence_indices]).sum()/len(confidence_indices[0])\n",
        "print(f\"The accuracy of the {len(confidence_indices[0])} points with confidence gap {confidence_gap} around point of interest {poi_pred_prob} is {calibration_error_acc}\")\n",
        "print(f\"The gap between the accuracy and the ground truth probability of the POI is {abs(calibration_error_acc - poi_gt_prob)}\")\n",
        "\n",
        "\n",
        "eps = 0.61\n",
        "poi_data_around = poi_data + np.random.uniform(-eps, eps, size=(1000,) + poi_data.shape)\n",
        "\n",
        "# calculate the predicted label of these neighboring points\n",
        "output_labels_around = model(torch.from_numpy(poi_data_around).float())\n",
        "pred_labels_around = torch.max(output_labels_around, dim=1)[1]\n",
        "pred_labels_conf = torch.max(F.softmax(output_labels_around, dim=1), dim=1)[0]\n",
        "\n",
        "\n",
        "aggregation_result = pred_labels_around.sum()/len(pred_labels_around)\n",
        "aggregation_result = max(aggregation_result.item(), 1 - aggregation_result.item())\n",
        "print(f\"The consistency eps: {eps:.2f}, pred_labels_around: {aggregation_result}\")\n",
        "print(f\"The gap between the consistency (eps={eps:.2f}) and the ground truth probability of the POI is {abs(aggregation_result - poi_gt_prob)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(1000):\n",
        "    # sample 1000 points around the poi_data, the distance is sampled from a uniform distribution between 0 and 0.1\n",
        "    eps = i/1000\n",
        "    poi_data_around = poi_data + np.random.uniform(-eps, eps, size=(1000,) + poi_data.shape)\n",
        "\n",
        "    # calculate the predicted label of these neighboring points\n",
        "    output_labels_around = model(torch.from_numpy(poi_data_around).float())\n",
        "    pred_labels_around = torch.max(output_labels_around, dim=1)[1]\n",
        "    pred_labels_conf = torch.max(F.softmax(output_labels_around), dim=1)[0]\n",
        "\n",
        "    \n",
        "    aggregation_result = pred_labels_around.sum()/len(pred_labels_around)\n",
        "    print(\"eps: \", eps, \"pred_labels_around: \", aggregation_result if aggregation_result > 0.5 else 1 - aggregation_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "KAzqe7rA7jjG",
        "outputId": "dc38d16b-b282-4bfc-cbaf-ad10d48b3ba0"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(np.flip(pred_probs.reshape(num_x, num_y), axis=0),cmap='jet')\n",
        "cbar = fig.colorbar(im)\n",
        "cbar.set_ticks([0,.25,.5,.75,1])\n",
        "cbar.set_ticklabels([0,.25,.5,.75,1])\n",
        "cbar.outline.set_linewidth(0)\n",
        "ax.axis(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "_-yuG-NE9PLs",
        "outputId": "7ffedf51-23a1-4cff-cb9d-762437ed0b03"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(np.flip(gt_probs.reshape(num_x, num_y), axis=0),cmap='jet')\n",
        "cbar = fig.colorbar(im)\n",
        "cbar.set_ticks([0,.25,.5,.75,1])\n",
        "cbar.set_ticklabels([0,.25,.5,.75,1])\n",
        "cbar.outline.set_linewidth(0)\n",
        "ax.axis(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "EpHNkW4RAGW0",
        "outputId": "0fae517a-1d05-41a1-8a94-32827fe15150"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(np.flip((pred_probs-gt_probs).reshape(num_x, num_y), axis=0),cmap='hsv')\n",
        "cbar = fig.colorbar(im)\n",
        "cbar.set_ticks([-.2, -.1, 0,.1, .2])\n",
        "cbar.set_ticklabels([-.2, -.1, 0,.1, .2])\n",
        "cbar.outline.set_linewidth(0)\n",
        "ax.axis(False)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
